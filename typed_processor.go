package kprocessor

import (
	"context"
	"fmt"
	"time"

	"github.com/twmb/franz-go/pkg/kgo"
)

type RecordContext struct {
	// Headers are optional key/value pairs that are passed along with
	// records.
	//
	// These are purely for producers and consumers; Kafka does not look at
	// this field and only writes it to disk.
	Headers []kgo.RecordHeader

	// NOTE: if logAppendTime, timestamp is MaxTimestamp, not first + delta
	// zendesk/ruby-kafka#706

	// Timestamp is the timestamp that will be used for this record.
	//
	// Record batches are always written with "CreateTime", meaning that
	// timestamps are generated by clients rather than brokers.
	//
	// When producing, if this field is not yet set, it is set to time.Now.
	Timestamp time.Time

	// Topic is the topic that a record is written to.
	//
	// This must be set for producing.
	Topic string

	// Partition is the partition that a record is written to.
	//
	// For producing, this is left unset. This will be set by the client as
	// appropriate. Alternatively, you can use the ManualPartitioner, which
	// makes it such that this field is always the field chosen when
	// partitioning (i.e., you partition manually ahead of time).
	Partition int32

	// Attrs specifies what attributes were on this record.
	Attrs kgo.RecordAttrs

	// ProducerEpoch is the producer epoch of this message if it was
	// produced with a producer ID. An epoch and ID of 0 means it was not.
	//
	// For producing, this is left unset. This will be set by the client
	// as appropriate.
	ProducerEpoch int16

	// ProducerEpoch is the producer ID of this message if it was produced
	// with a producer ID. An epoch and ID of 0 means it was not.
	//
	// For producing, this is left unset. This will be set by the client
	// as appropriate.
	ProducerID int64

	// LeaderEpoch is the leader epoch of the broker at the time this
	// record was written, or -1 if on message sets.
	//
	// For committing records, it is not recommended to modify the
	// LeaderEpoch. Clients use the LeaderEpoch for data loss detection.
	LeaderEpoch int32

	// Offset is the offset that a record is written as.
	//
	// For producing, this is left unset. This will be set by the client as
	// appropriate. If you are producing with no acks, this will just be
	// the offset used in the produce request and does not mirror the
	// offset actually stored within Kafka.
	Offset int64
}

type TypedProcessor[K any, V any] interface {
	Process(ctx context.Context, key K, value V, record RecordContext) error
}

func FromTypedProcessor[K any, V any](
	p TypedProcessor[K, V],
	keyDeserializer Deserializer[K],
	valueDeserializer Deserializer[V],
) Processor {
	return ProcessorFunc(func(ctx context.Context, record *kgo.Record) error {
		key, err := keyDeserializer(record.Key)
		if err != nil {
			return fmt.Errorf("FromTypedProcessor: failed to deserialize key from byte array, %w", err)
		}

		value, err := valueDeserializer(record.Value)
		if err != nil {
			return fmt.Errorf("FromTypedProcessor: failed to deserialize value from byte array, %w", err)
		}

		return p.Process(ctx, key, value, RecordContext{
			Headers:       record.Headers,
			Timestamp:     record.Timestamp,
			Topic:         record.Topic,
			Partition:     record.Partition,
			Attrs:         record.Attrs,
			ProducerEpoch: record.ProducerEpoch,
			ProducerID:    record.ProducerID,
			LeaderEpoch:   record.LeaderEpoch,
			Offset:        record.Offset,
		})
	})
}
